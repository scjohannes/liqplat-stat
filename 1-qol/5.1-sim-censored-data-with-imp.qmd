---
Title: Simulating Characteristics
---

Here we explore if we can use multiple imputation to fill in the censored values and still get correct SOPs. This is WIP.

## Setup

```{r}
library(ggplot2)
library(arrow)
library(tidyverse)
library(furrr)
library(mice)
library(miceadds)
library(VGAM)
```

## Load data

```{r}
df_full <- read_parquet("./1-qol/sim-data/sim_data_po.parquet")

source("./functions/censor-qol-data.R")
source("./functions/write-sops.R")
source("./functions/carry-death-forward.R")
```

## Multiple Imputation

First, we want to check whether we can in principle recover the OR of 0.8 and the difference in time spent with >= good QoL if we only observe about 4 measurements per patient. 

### Sample data for 2500 patients

```{r}
set.seed(1234)

ss_tx <- 1250
ss_control <- 1250

tx_ids <- sample(df_full |> filter(tx == 1) |> pull(id) |> unique(), ss_tx, replace = F)
control_ids <- sample(df_full |> filter(tx == 0) |> pull(id) |> unique(), ss_control, replace = F)

df <- df_full |> 
    filter(id %in% tx_ids | id %in% control_ids)
```

## Separate first row and row where y == 8

```{r}
first_rows <- df |> 
  group_by(id) |> 
  arrange(id, time) |> 
  slice_head(n = 1)

death_rows <- df |> 
    filter(y == '8')
```

## Take random sample of other rows

```{r}
sample_rows <- df |> 
    anti_join(first_rows) |> 
    anti_join(death_rows) |> 
    ungroup() |> 
    slice_sample(prop = 0.15) |> # this should amount to roughly four quality of life measurements after the baseline measurement 
    arrange(id, time)
```

## Data wrangling

- We have to recompute yprev and add a gap time between the measurements

```{r}
baseline <- first_rows |> 
    mutate(
      y = yprev,
      time = 0
    ) |> 
    select(-yprev)

follow_up <- sample_rows |> 
    bind_rows(death_rows) |> 
    select(-yprev) |> 
    bind_rows(baseline) |> 
    arrange(id, time)

follow_up <- follow_up |> 
    group_by(id) |> 
    mutate(
        yprev = case_when(
            TRUE ~ lag(y, n = 1, order_by = time)
        ),
        yprev = factor(yprev, levels = 1:7, ordered = FALSE), #death = 8 doesn't exist in yprev
        timeprev = case_when(
            TRUE ~ lag(time, n = 1, order_by = time)
        ), 
        gap = time - timeprev) |> 
    slice(-1) |> #remove baseline without prior state
    ungroup()
```

## Visualize follow-pattern

- As expected, we have datapoints for the entire follow-up duration (i.e., for every week)

```{r}
follow_up |> 
    ggplot(aes(x = time, y = y)) +
    geom_jitter(width = 0.1, height = 0.1)
```

## Imputing all missing y


### create dataset without QoL measurements

```{r}
measurements <- follow_up |> bind_rows(baseline) |> select(id, y, time)

static_info <- follow_up |> 
  group_by(id) |> 
  mutate(
    dweek = time[y=='8'][1],
    status = if_else(!is.na(dweek), 1, 0)) |> 
  ungroup() |> 
  select(-time, -y, -yprev, -gap, -timeprev) |> 
  distinct()
  
empty_obs <-  static_info |>
  mutate(time = list(0:26)) |>
  unnest(time) |> 
  left_join(measurements, by = c("id", "time")) |> 
  mutate(
    dweek = if_else(is.na(dweek), 27, dweek),
    y = factor(y, levels = 1:7, ordered = TRUE),
    status = factor(status),
    tx = factor(tx),
    ) |> 
  arrange(id, time) |> 
  group_by(id) |> 
  filter(row_number() - 1 < dweek) |> 
  select(-gender, -pat_age, -plan_fstcnt_coded) #I know that these variables are not predictive
```

### Impute this dataset

```{r}
md.pattern(empty_obs)

init <- mice(empty_obs, maxit = 0)
pred_matrix <- init$predictorMatrix
meth <- init$method

# Use patient ID as clustering variable
pred_matrix[, "id"] <- -2

# Impute individual q30 at the questionnaire level
meth["y"] <- "2l.pmm"


imputed_data <- mice(empty_obs,
                     m = 10,
                     maxit = 50,
                     predictorMatrix = pred_matrix,
                     method = meth,
                     seed = 123)

plot(imputed_data)
densityplot(imputed_data, ~y)

stripplot(imputed_data, y ~ .imp, pch = 20, cex = 1.2)

death_rows <- death_rows |> 
  mutate(
    tx = factor(tx),
    status = factor(status)
  ) |> 
  select(-pat_age, -plan_fstcnt_coded, -yprev, -gender)

complete_data <- list()

for (i in 1:10){
  imputed_set <- complete(imputed_data, i)

  imputed_set <- imputed_set |> 
    mutate(y = factor(y, ordered = FALSE)) |> 
    bind_rows(death_rows) |> 
    arrange(id, time) |> 
    group_by(id) |> 
    mutate(yprev = case_when(
              TRUE ~ lag(y, n = 1, order_by = time))) |> 
    slice(-1) |> 
    ungroup() |> 
    mutate(
      y = as.numeric(as.character(y)),
      yprev = factor(yprev, ordered = F))
  
  complete_data[[i]] <- imputed_set
}
```

### Fit VGAM model

```{r}
# original full data
o <- vglm(ordered(y) ~ tx + poly(time, 2) + yprev + ecog_fstcnt + diagnosis, 
  cumulative(reverse = TRUE, parallel = FALSE ~ poly(time, 2)), 
  data = df)

f <- vglm(ordered(y) ~ tx + poly(time, 2) + yprev + ecog_fstcnt + diagnosis, 
  cumulative(reverse = TRUE, parallel = FALSE ~ poly(time, 2)), 
  data = complete_data)

cbind(o = coef(o), f = coef(f))
```

```{r}
models_list <- list()

for (i in 1:length(complete_data)) {
  current_data <- complete_data[[i]]
  
  model_fit <- vglm(ordered(y) ~ tx + poly(time, 2) + yprev + ecog_fstcnt + diagnosis, 
                    cumulative(reverse = TRUE, parallel = FALSE ~ poly(time, 2)), 
                    data = current_data)

  models_list[[i]] <- model_fit
}

coefficients_list <- list()

for (i in 1:length(models_list)) {
  current_coefficients <- coef(models_list[[i]])
  
  coefficients_df <- enframe(current_coefficients, name = "term", value = "estimate")
  
  coefficients_list[[i]] <- coefficients_df
}

all_coefficients_df <- bind_rows(coefficients_list, .id = "imputation_id")

mean_coefficients <- all_coefficients_df |> 
  group_by(term) |> 
  summarise(mean_estimate = mean(estimate, na.rm = TRUE)) |> 
  arrange(term)

true_coefficients <- enframe(coef(o), name = 'term', value = 'estimate') |> 
  arrange(term)

bind_cols(mean_coefficients, true_coefficients) |> View()
```

The esimated OR is around 0.8, but probably 25000 patients with about 5 measurements each are not enough.